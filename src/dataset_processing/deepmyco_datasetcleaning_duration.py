# -*- coding: utf-8 -*-
"""DeepMyco-DatasetCleaning-Duration.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QT6JkUWfLYdTEA_bJ9oBoKx4Nq7Ga0Nv
"""

# =========================================
# 1. Setup & load data
# =========================================
import pandas as pd
import numpy as np
import re
import os

# OPTION A: If your file is in Google Drive
# from google.colab import drive
# drive.mount('/content/drive')
# folder_path = "/content/drive/MyDrive/DeepMyco"  # <-- change to your folder
# input_path = os.path.join(folder_path, "merged_dataset_temp_cleaned.csv")

# OPTION B: If your file is in the Colab working directory
input_path = "/content/merged_dataset_temp_cleaned.csv"  # <-- change if needed

df = pd.read_csv(input_path)

if "duration" not in df.columns:
    raise ValueError("Column 'duration' not found in the dataset.")

print("Sample raw duration values BEFORE cleaning:")
print(df["duration"].value_counts().head(30))

# =========================================
# 2. Duration parsing helper
#    -> returns a float in HOURS or NaN
# =========================================

def parse_duration_to_hours(value):
    """
    Parse a messy duration string into a numeric value in HOURS.
    Handles:
      - '24 h', '24h', '24 hr', '24 hours'
      - '2 days', '3 d', '3-day', '5 days incubation'
      - '120 min', '30 minutes'
      - ranges like '24-48 h', 'from 2 to 3 days', 'between 12 and 18 h' -> avg
      - '24/48 h' (two durations) -> avg
      - 'up to 7 days', 'within 24 h' -> uses number present
      - explicit 'not specified', 'unknown', etc. -> NaN

    Assumptions:
      - If 'day'/'d'/'days' present -> numbers are days (converted to hours)
      - Else if 'week' present -> numbers are weeks (converted to hours)
      - Else if 'min' present -> numbers are minutes (converted to hours)
      - Else -> numbers are hours
    """
    v = str(value).strip()
    low = v.lower()

    # Explicit missing/unknown tokens
    missing_tokens = {
        "not specified", "unspecified", "unknown", "not applicable",
        "not specified (bacteria)", "number not specified", "--",
        "no data", "not mentioned", "not available"
    }
    if v == "" or low in missing_tokens:
        return np.nan

    # Obvious non-duration descriptors
    if any(phrase in low for phrase in [
        "various", "different durations", "time course", "continuous", "intermittent"
    ]):
        # Too vague to turn into a single number
        return np.nan

    # Extract all numbers (allow decimals, comma as decimal separator)
    nums_str = re.findall(r"\d+\.?\d*", v.replace(",", "."))
    if not nums_str:
        return np.nan

    nums = [float(x) for x in nums_str]

    # Decide unit from text
    is_day = any(term in low for term in [" day", " days", " d "]) or low.endswith("days") or low.endswith(" day") or low.endswith(" d")
    is_week = "week" in low
    is_min = "min" in low or "minute" in low

    # Range-like tokens
    range_tokens = [" to ", "between", "from", "-", "–", " and ", "/"]

    # Helper: interpret numeric value(s) under detected unit
    def convert_values_to_hours(values):
        if is_week:
            # weeks -> hours
            vals_in_h = [v * 24 * 7 for v in values]
        elif is_day:
            # days -> hours
            vals_in_h = [v * 24 for v in values]
        elif is_min:
            # minutes -> hours
            vals_in_h = [v / 60.0 for v in values]
        else:
            # default: hours
            vals_in_h = values
        return vals_in_h

    # If we have more than one number and clearly a range or dual value,
    # take the average of the first two.
    if len(nums) >= 2 and any(tok in low for tok in range_tokens):
        vals_h = convert_values_to_hours(nums[:2])
        return sum(vals_h) / 2.0

    # If we see something like "24/48 h" but didn't catch above, handle "/"
    if len(nums) >= 2 and "/" in v:
        vals_h = convert_values_to_hours(nums[:2])
        return sum(vals_h) / 2.0

    # Otherwise, just treat the first number as the duration
    vals_h = convert_values_to_hours([nums[0]])
    return vals_h[0]

# =========================================
# 3. Apply cleaning to create duration_h
# =========================================

df["duration"] = df["duration"].astype(str).str.strip()
df["duration_h"] = df["duration"].apply(parse_duration_to_hours)

print("\nSummary of cleaned numeric duration (hours):")
print(df["duration_h"].describe())

print("\nNumber of rows with missing duration_h:", df["duration_h"].isna().sum())

# Show what raw values failed to parse
unparsed = df.loc[df["duration_h"].isna(), "duration"].value_counts()
print("\nRaw duration strings that were NOT parsed (treated as NaN):")
print(unparsed)

# =========================================
# 4. Save cleaned file
# =========================================

# If you mounted Drive and used folder_path:
# output_path = os.path.join(folder_path, "merged_dataset_duration_cleaned.csv")

output_path = "/content/merged_dataset_duration_cleaned.csv"  # <-- adjust if needed
df.to_csv(output_path, index=False)

print(f"\n✅ Saved dataset with cleaned duration to: {output_path}")