# -*- coding: utf-8 -*-
"""DeepMyco-DatasetCleaning-FungiNames.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1C4d7h40bHILKyXqy6YO1H3jp5hMlNRE6
"""

# =========================================
# 1. Setup & load data
# =========================================
import pandas as pd
import re
import os

# OPTION A: If your file is in Google Drive
# from google.colab import drive
# drive.mount('/content/drive')
# folder_path = "/content/drive/MyDrive/DeepMyco"  # <-- change to your folder
# input_path = os.path.join(folder_path, "merged_dataset_dyes_cleaned.csv")

# OPTION B: If your file is in the Colab working directory
input_path = "/content/merged_dataset_dyes_cleaned.csv"  # <-- change if needed

df = pd.read_csv(input_path)

if "type_of_fungi" not in df.columns:
    raise ValueError("Column 'type_of_fungi' not found in the dataset.")

print("Unique fungi names BEFORE cleaning:", df["type_of_fungi"].nunique())
print(df["type_of_fungi"].value_counts().head(20))

# =========================================
# 2. Helper: build mapping for fungi names
#    - Unify 'not specified' / 'not applicable'
#    - Expand genus abbreviations (A. niger -> Aspergillus niger, etc.)
#      when a clear full form exists in the dataset
# =========================================

def build_fungi_mapping_strict(names):
    # Work on a clean Series of strings
    s = pd.Series(names).astype(str).str.strip()
    unique = sorted(s.unique())
    mapping = {}

    # --- 2a. Normalize obvious text variants ---
    for name in unique:
        low = name.lower().strip()
        if low == "not applicable":
            mapping[name] = "Not applicable"
        elif low == "not specified":
            mapping[name] = "Not specified"
        elif low == "not specified (bacteria)":
            mapping[name] = "Not specified"

    # --- 2b. Build candidate full names for genus+species ---
    # Key: (initial_with_dot, species) -> list of full names
    # e.g., ('A.', 'niger') -> ['Aspergillus niger', 'Aspergillus niger D2-1', ...]
    full_candidates = {}
    for name in unique:
        tokens = name.split()
        if not tokens:
            continue
        # Skip abbreviations here; only full names
        if tokens[0].endswith('.'):
            continue
        if len(tokens) >= 2:
            key = (tokens[0][0] + ".", tokens[1])
            full_candidates.setdefault(key, []).append(name)

    # --- 2c. Map abbreviated forms to full names when safe ---
    abbr_names = [n for n in unique if n and n.split()[0].endswith(".")]

    for abbr in abbr_names:
        toks = abbr.split()
        if len(toks) < 2:
            continue

        key = (toks[0], toks[1])  # ('A.', 'niger'), etc.
        cands = full_candidates.get(key)
        if not cands:
            continue

        # Extra tokens beyond genus+species (e.g., strain codes)
        extra = toks[2:]

        if extra:
            # Only map if we find a full name that contains ALL extra tokens
            def matches_extra(c):
                c_tokens = c.split()
                return all(e in c_tokens for e in extra)

            filtered = [c for c in cands if matches_extra(c)]
            if not filtered:
                # No good strain-level match; don't map this abbreviation
                continue
        else:
            filtered = cands

        # Among candidates, pick the shortest (fewest tokens), tie-break by lexicographic order
        best = sorted(filtered, key=lambda x: (len(x.split()), x))[0]
        mapping[abbr] = best

    return mapping

# Build the mapping from the actual data
fungi_mapping = build_fungi_mapping_strict(df["type_of_fungi"])

print("\nFungi mapping (abbreviations & variants -> canonical):")
for old, new in list(fungi_mapping.items())[:40]:
    print(f"  {old!r} -> {new!r}")
print(f"\nTotal mapped fungi names: {len(fungi_mapping)}")

# =========================================
# 3. Apply mapping to create a cleaned fungi column
# =========================================

df["type_of_fungi"] = df["type_of_fungi"].astype(str).str.strip()
df["type_of_fungi_clean"] = df["type_of_fungi"].replace(fungi_mapping)

print("\nUnique fungi names AFTER cleaning (using 'type_of_fungi_clean'):")
print(df["type_of_fungi_clean"].nunique())
print(df["type_of_fungi_clean"].value_counts().head(20))

# Show examples where the name changed
changed = df[df["type_of_fungi"] != df["type_of_fungi_clean"]][
    ["type_of_fungi", "type_of_fungi_clean"]
].drop_duplicates()

print("\nExamples of changed fungi names:")
print(changed.head(50))

# =========================================
# 4. Save cleaned file
# =========================================

# If you mounted Drive and used folder_path:
# output_path = os.path.join(folder_path, "merged_dataset_fungi_cleaned.csv")

output_path = "/content/merged_dataset_fungi_cleaned.csv"  # <-- adjust if needed
df.to_csv(output_path, index=False)

print(f"\nâœ… Saved dataset with cleaned fungi names to: {output_path}")